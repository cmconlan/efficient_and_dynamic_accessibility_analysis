{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End to end\n",
    "\n",
    "Process\n",
    "\n",
    "\n",
    "- Load neccessary data\n",
    "- Repeat following 10 times\n",
    "- Randomly select OAs and POIs to form an area of study\n",
    "- Randomly select a weekday, weekend, bank holiday from period of study\n",
    "- Cost trips on OTP (and OTP2 / r5?)\n",
    "- Run matrix spasification techniques\n",
    "    - knn\n",
    "    - spatial clustering\n",
    "    - flow clustering\n",
    "    - gravity trip generator\n",
    "- Reduce results as much as possible without loss of information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module imports\n",
    "\n",
    "todo: check to see if any unneccsary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import Point\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt,exp,pow\n",
    "import math\n",
    "import statistics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import HDBSCAN\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def distance_decay(distance, decay_constant, exponent):\n",
    "    return exp(-decay_constant * pow(distance, exponent))\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the haversine distance between two points given their latitude and longitude.\n",
    "\n",
    "    Parameters:\n",
    "    - lat1, lon1: Latitude and longitude of the first point (in degrees)\n",
    "    - lat2, lon2: Latitude and longitude of the second point (in degrees)\n",
    "\n",
    "    Returns:\n",
    "    The haversine distance in kilometers.\n",
    "    \"\"\"\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    # Radius of the Earth in kilometers (mean value)\n",
    "    earth_radius = 6371.0\n",
    "\n",
    "    # Calculate the haversine distance\n",
    "    distance = earth_radius * c\n",
    "\n",
    "    return distance\n",
    "\n",
    "def flowProx(flow_i,flow_j, alpha=1, beta=1, gamma=1):\n",
    "    dist = (alpha*((flow_i[0] - flow_j[0]) ** 2) + beta*(((flow_i[2] - flow_j[2]) ** 2) + ((flow_i[3] - flow_j[3]) ** 2))) / ((haversine_distance(flow_i[0],flow_i[1],flow_i[2],flow_i[3]) * haversine_distance(flow_j[0],flow_j[1],flow_j[2],flow_j[3]))**gamma)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def getminreach(xi,xj):\n",
    "    flow_i=tuple([xi[0],xi[1],xi[2],xi[3]])\n",
    "    flow_j=tuple([xj[0],xj[1],xj[2],xj[3]])\n",
    "    CDi = xi[4]\n",
    "    CDj = xj[4]\n",
    "    prox_dist = flowProx(flow_i,flow_j, alpha=1, beta=1, gamma=1)\n",
    "    mreachd = max(CDi,CDj,prox_dist)\n",
    "    return mreachd\n",
    "\n",
    "def get_flow_dist_mx(oaSample,POISample,minflows,flowProx):\n",
    "    flows_index = []\n",
    "    o_index = []\n",
    "    d_index = []\n",
    "    flows = []\n",
    "\n",
    "    oind = 0\n",
    "    for o in oaSample[['oa_lat','oa_lon','oa_id']].values:\n",
    "        dind = 0\n",
    "        for d in POISample[['poi_lon','poi_lat','poi_id']].values:\n",
    "            flows.append(tuple([o[0], o[1], d[0], d[1]]))\n",
    "            flows_index.append(tuple([o[2],int(d[2])]))\n",
    "            o_index.append(o[2])\n",
    "            d_index.append(int(d[2]))\n",
    "            dind += 1\n",
    "        oind += 1\n",
    "\n",
    "    # Calculate CoreD\n",
    "    # Create a NearestNeighbors object with a custom distance function\n",
    "    neighbors_model = NearestNeighbors(n_neighbors=minflows, algorithm='ball_tree', metric=flowProx)\n",
    "    X = np.array(flows)\n",
    "    # Fit the model to your data\n",
    "    neighbors_model.fit(X)\n",
    "\n",
    "    core_distances = []\n",
    "    count = 0\n",
    "    for i in X:\n",
    "        distances, indices = neighbors_model.kneighbors([i])\n",
    "        core_distances.append(distances[:, -1][0])\n",
    "\n",
    "    lst_reshaped = np.array(core_distances).reshape((len(core_distances), 1))\n",
    "    return np.concatenate((X, lst_reshaped), axis=1), o_index, d_index, flows, flows_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up code paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Time Stamps / Time Interval\n",
    "\n",
    "stratumDict = {\n",
    "    'amPeak':{\n",
    "        'startHour' : 6,\n",
    "        'startMinute' : 30,\n",
    "        'endHour' : 8,\n",
    "        'endMinute' : 30\n",
    "        },\n",
    "    'Saturday':{\n",
    "        'startHour' : 10,\n",
    "        'startMinute' : 00,\n",
    "        'endHour' : 18,\n",
    "        'endMinute' : 00\n",
    "        },\n",
    "    'bh':{\n",
    "        'startHour' : 10,\n",
    "        'startMinute' : 00,\n",
    "        'endHour' : 18,\n",
    "        'endMinute' : 00\n",
    "        }\n",
    "    }\n",
    "\n",
    "#Params\n",
    "decay_constant = 1\n",
    "exponent = 0.2\n",
    "#Integer for 1 trip per x minutes. E.g., 1 = a trip every minutes. 5 = 1 trip every 5 minutes\n",
    "# For now go with every minutes but may pull this back\n",
    "# To do - revisit later on\n",
    "temp_resolution = 1\n",
    "\n",
    "num_iterations = 10\n",
    "\n",
    "num_oas = 200\n",
    "num_pois = 50\n",
    "\n",
    "# Vectrise distance decay function\n",
    "vfunc = np.vectorize(distance_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get day index\n",
    "# Specify the start and end dates\n",
    "start_date = '2024-03-15'\n",
    "end_date = '2024-04-15'\n",
    "\n",
    "# Create a date-time index\n",
    "date_index = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "experiment_dates = pd.DataFrame(index = date_index)\n",
    "\n",
    "experiment_dates['weekday'] = experiment_dates.index.weekday < 5\n",
    "experiment_dates['saturday'] = experiment_dates.index.weekday == 5\n",
    "bank_holidays = ['2024-03-29', '2024-04-01']\n",
    "experiment_dates['bank_holiday'] = experiment_dates.index.isin(pd.to_datetime(bank_holidays))\n",
    "\n",
    "# Get OAs\n",
    "wm_oas = gpd.read_file('data/west_midlands_OAs/west_midlands_OAs.shp')\n",
    "wm_oas = wm_oas[wm_oas['LAD11CD'] == 'E08000026']\n",
    "oa_info = pd.read_csv('data/oa_info.csv')\n",
    "oa_info = oa_info.merge(wm_oas[['OA11CD']], left_on = 'oa_id', right_on = 'OA11CD', how = 'inner')\n",
    "oaLatLon = oa_info[['oa_id','oa_lon','oa_lat']]\n",
    "\n",
    "# Get POIs\n",
    "pois = pd.read_csv('data/POIs/pois_cov.csv', index_col=0)\n",
    "\n",
    "# Generate POI attractiveness using gaussian randomness\n",
    "\n",
    "mean = 50\n",
    "std_dev = 20\n",
    "attractivnessDict = {}\n",
    "\n",
    "for pid in list(pois['poi_id']):\n",
    "    random_value = random.normalvariate(mean, std_dev)\n",
    "    attractivnessDict[pid] = max(min(random_value, 100), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tracking matrices\n",
    "\n",
    "performance = {}\n",
    "processing_times = {}\n",
    "for i in range(num_iterations):\n",
    "    performance[i] = {}\n",
    "    processing_times[i] = {}\n",
    "    for k in list(stratumDict.keys()):\n",
    "        performance[i][k] = {}\n",
    "        processing_times[i][k] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do - decide number of iterations. What is easily defensible? 10?\n",
    "\n",
    "iteration = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an iteration select random OAs and POI - get from old code don't need to re-invent this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample 200 random zones\n",
    "oaSample = oa_info.sample(num_oas)[['oa_id','oa_lat','oa_lon']]\n",
    "\n",
    "#POIs\n",
    "POISample = pois.sample(num_pois)\n",
    "POISample['attractiveness'] = POISample['poi_id'].map(attractivnessDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define time domain\n",
    "\n",
    "\n",
    "to do:\n",
    "\n",
    "- Update to dynamically select at correct temporal granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratum = 'amPeak'\n",
    "\n",
    "if stratum == 'amPeak':\n",
    "    study_date = experiment_dates[(experiment_dates['weekday']) & (experiment_dates['bank_holiday'] == False)].sample(1).index\n",
    "\n",
    "elif stratum == 'Saturday':\n",
    "    study_date = experiment_dates[(experiment_dates['saturday']) & (experiment_dates['bank_holiday'] == False)].sample(1).index\n",
    "\n",
    "elif stratum == 'bh':\n",
    "    study_date = experiment_dates[experiment_dates['bank_holiday']].sample(1).index\n",
    "\n",
    "# Create Time Domain\n",
    "startHour = stratumDict[stratum]['startHour']\n",
    "startMinute = stratumDict[stratum]['startMinute']\n",
    "endHour = stratumDict[stratum]['endHour']\n",
    "endMinute = stratumDict[stratum]['endMinute']\n",
    "\n",
    "start = datetime(year=2012, month=2, day=25, hour=startHour, minute = startMinute)\n",
    "end = datetime(year=2012, month=2, day=25, hour=endHour, minute = endMinute)\n",
    "diff = end - start\n",
    "minutesInInterval = diff.total_seconds()/60\n",
    "hoursInInterval = minutesInInterval/60\n",
    "\n",
    "num_trips = int((60 / temp_resolution) * hoursInInterval)\n",
    "\n",
    "timeDomain = []\n",
    "\n",
    "for i in range(num_trips):\n",
    "    randStartTime = start + timedelta(minutes=random.randint(1, int(minutesInInterval)))\n",
    "    if randStartTime not in timeDomain:\n",
    "        timeDomain.append(str(randStartTime.hour).zfill(2)+':'+str(randStartTime.minute).zfill(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output trips to CSV\n",
    "\n",
    "temp_trips_file = 'tempdata/trips_to_route.csv'\n",
    "output_file = open(temp_trips_file, 'w')\n",
    "writer = csv.writer(output_file)\n",
    "writer.writerow(['oa_id','poi_id','trip_id','date','time','oa_lat','oa_lon','poi_lat','poi_lon'])\n",
    "\n",
    "#Output trips dataset - output csv with following: \n",
    "trip_id = 0\n",
    "#trip_date = study_date[0].strftime('%m/%d/%Y')\n",
    "trip_date = study_date[0].strftime('%Y-%m-%d')\n",
    "\n",
    "for oind, orow in oaSample.iterrows():\n",
    "    for pind,prow in POISample.iterrows():\n",
    "        for t in timeDomain:            \n",
    "            row = [orow['oa_id'],prow['poi_id'],trip_id,trip_date,t,orow['oa_lat'], orow['oa_lon'],prow['poi_lat'], prow['poi_lon']]\n",
    "            writer.writerow(row)\n",
    "            trip_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost trips on OTP using parallelisation\n",
    "\n",
    "num_trips = num_rows(temp_trips_file)\n",
    "step_size = get_step_size(num_trips, processes)\n",
    "\n",
    "args = []\n",
    "for i in range(processes):\n",
    "    host_url = f\"http://{host}:{str(port + (i % otps))}\"\n",
    "    offset =i * step_size\n",
    "    arg = (\n",
    "        host_url, \n",
    "        offset, \n",
    "        min(offset+step_size, num_trips), \n",
    "        temp_trips_file, \n",
    "        'tempdata'\n",
    "    )\n",
    "    args.append(arg)\n",
    "\n",
    "rows_complete = multiprocessing.Value('i', 0)\n",
    "\n",
    "t0_routing_cost = time.time()\n",
    "with multiprocessing.Pool(int(processes), initializer=init, initargs=(num_trips, rows_complete)) as pool:\n",
    "    results = pool.starmap(compute_trips, args)\n",
    "t1_routing_cost = time.time()\n",
    "print('Time Taken : {}'.format(t1_routing_cost - t0_routing_cost))\n",
    "\n",
    "files = []\n",
    "bad_rows = 0\n",
    "for f, rows in results:\n",
    "    files.append(f)\n",
    "    bad_rows += rows\n",
    "if bad_rows > 0:\n",
    "    print(f\"{bad_rows} trips were lost during OTP processing ({(bad_rows/num_trips * 100):.2f}%).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output to CSV (needed)\n",
    "\n",
    "output_file_name = os.path.join('tempdata', 'results_full.csv')\n",
    "files_iterator = iter(files)\n",
    "# Treat the first file differently, so we can extract headers\n",
    "first_file = files[0]\n",
    "headers = extract_headers(first_file)\n",
    "with open(output_file_name, 'w') as output_file:\n",
    "    output_csv = csv.writer(output_file)\n",
    "    output_csv.writerow(headers)\n",
    "    for csv_file in files:\n",
    "        with open(csv_file, newline='') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for line in reader:\n",
    "                output_csv.writerow(line.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do\n",
    "\n",
    "- Develop costing script to either import here, or to be called with a parameter set\n",
    "- Send trip to costing script and ensure returns correct data type\n",
    "- Below probably to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os, urllib, json, csv, zipfile, math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Rows : 45000\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n",
      "36500\n",
      "37000\n",
      "37500\n",
      "38000\n",
      "38500\n",
      "39000\n",
      "39500\n",
      "40000\n",
      "40500\n",
      "41000\n",
      "41500\n",
      "42000\n",
      "42500\n",
      "43000\n",
      "43500\n",
      "44000\n",
      "44500\n"
     ]
    }
   ],
   "source": [
    "print('Num Rows : {}'.format(len(oaSample) * len(POISample) * len(timeDomain)))\n",
    "\n",
    "otp_url = 'http://localhost:8080/otp/routers/default/plan?'\n",
    "output_file = open('tempdata/tripscosts_otp.csv', 'w')\n",
    "writer = csv.writer(output_file)\n",
    "writer.writerow(['trip_id','date','time','oa_id','poi_id','itiniery_id','duration','walk_time','wait_time','transit_time','initial_wait_time','transfers','fare','routing_cost'])\n",
    "\n",
    "trip_id = 0\n",
    "itin_id = 0\n",
    "trip_date = study_date[0].strftime('%m/%d/%Y')\n",
    "\n",
    "failed_routes_list = []\n",
    "\n",
    "for oind, orow in oaSample.iterrows():\n",
    "    for pind,prow in POISample.iterrows():\n",
    "        for t in timeDomain:\n",
    "            if trip_id % 500 == 0:\n",
    "                print(trip_id)\n",
    "                \n",
    "            params = {}\n",
    "            params['date'] = trip_date\n",
    "            params['time'] = t\n",
    "            params['fromPlace'] = '%s,%s' % (orow['oa_lat'], orow['oa_lon'])\n",
    "            params['toPlace'] = '%s,%s' % (prow['poi_lat'], prow['poi_lon'])\n",
    "            params['mode'] = 'WALK,TRANSIT'\n",
    "            params['arriveBy'] = 'false'\n",
    "            params['numItineraries'] = '1'\n",
    "            params['walkReluctance'] = '20'\n",
    "\n",
    "            t0 = time.time()\n",
    "            req = urllib.request.Request(otp_url + urllib.parse.urlencode(params))\n",
    "            req.add_header('Accept', 'application/json')\n",
    "            response = urllib.request.urlopen(req)\n",
    "            content = response.read()\n",
    "            objs = json.loads(content)\n",
    "            t1 = time.time()\n",
    "\n",
    "            if len(objs['plan']['itineraries']) == 0:\n",
    "                fail_append = {}\n",
    "                fail_append['oa'] = orow['oa_id']\n",
    "                fail_append['poi'] = prow['poi_id']\n",
    "                fail_append['time'] = t\n",
    "                failed_routes_list.append(fail_append)\n",
    "                pass\n",
    "            else:\n",
    "                i = objs['plan']['itineraries'][0]\n",
    "\n",
    "            if i['transitTime'] == 0:\n",
    "                fare = 0\n",
    "            else:\n",
    "                fare = (i['transfers'] + 1) * 2.4\n",
    "\n",
    "            query_time = datetime.strptime(t, '%H:%M').time()\n",
    "            departure_time = datetime.fromtimestamp(float(i['startTime']) / 1000).time()\n",
    "            initial_wait_time = (datetime.combine(datetime.today(), departure_time) - datetime.combine(datetime.today(), query_time)).total_seconds()\n",
    "\n",
    "            row = [trip_id,trip_date,t,orow['oa_id'],prow['poi_id'],itin_id,i['duration'],i['walkTime'],i['waitingTime'],i['transitTime'],initial_wait_time,i['transfers'],fare,(t1-t0)]\n",
    "            writer.writerow(row)\n",
    "\n",
    "            trip_id += 1\n",
    "\n",
    "output_file.close()\n",
    "failed_routes = pd.DataFrame(failed_routes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_trips = pd.read_csv('tempdata/trips_to_route.csv').set_index('trip_id')\n",
    "trips = pd.read_csv('tempdata/results_full.csv').set_index('trip_id')\n",
    "trips = trips.merge(initial_trips[['poi_id','oa_id','time']],right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once testing done drop below script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63663/1142294112.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['attractiveness'] = POISample['poi_id'].map(attractivnessDict)\n"
     ]
    }
   ],
   "source": [
    "#Sample 200 random zones\n",
    "oaSample = oa_info[oa_info['oa_id'].isin(list(set(trips['oa_id'])))][['oa_id','oa_lat','oa_lon']]\n",
    "\n",
    "#POIs\n",
    "POISample = pois[pois['poi_id'].isin(list(set(trips['poi_id'])))]\n",
    "POISample['attractiveness'] = POISample['poi_id'].map(attractivnessDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict type:\n",
    "    # key OAid - dict\n",
    "        # key POIid - list\n",
    "            # List of trip IDs\n",
    "\n",
    "oa_poi_id_dict = {}\n",
    "\n",
    "for oa_id in list(oaSample['oa_id']):\n",
    "    oa_poi_id_dict[oa_id] = {}\n",
    "    for poi_id in list(POISample['poi_id']):\n",
    "        oa_poi_id_dict[oa_id][poi_id] = list(trips[(trips['oa_id'] == oa_id) & (trips['poi_id'] == poi_id)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "peformance_mx = pd.DataFrame(index = list(oaSample['oa_id']))\n",
    "costing_mx = pd.DataFrame(index = list(oaSample['oa_id']))\n",
    "computing_times = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gravity model run\n"
     ]
    }
   ],
   "source": [
    "#Compute generalised access cost\n",
    "trips['gac'] = (( 1.5 * (trips['total_time'])) - (0.5 * trips['transit_time']) + ((trips['fare'] * 3600) / 6.7) + (10 * trips['num_transfers'])) / 60\n",
    "trips['att'] = trips['poi_id'].map(attractivnessDict)\n",
    "\n",
    "#Gravity Model Ground Truth\n",
    "trips['dist decay'] = vfunc(np.array(trips['gac']),decay_constant, exponent)\n",
    "trips['grav'] = trips['dist decay'] * trips['att']\n",
    "gravity = trips.groupby('oa_id').sum()['grav']\n",
    "print('Gravity model run')\n",
    "\n",
    "peformance_mx['GM'] = gravity\n",
    "costing_mx['GM'] = trips.groupby('oa_id').sum()['queryTime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Results KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do\n",
    "\n",
    "- Which values of k? Maybe just 5, 15, 25\n",
    "- Collect metrics in tracking dicts\n",
    "- Add time trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [5,15,25]:\n",
    "\n",
    "    processing_time = 0\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    knn.fit(POISample[['poi_lon','poi_lat']].values)\n",
    "    kResList = []\n",
    "    countOrigins = 0\n",
    "\n",
    "    t1 = time.time()\n",
    "    processing_time += (t1 - t0)\n",
    "\n",
    "    for oind, orow in oaSample.iterrows():\n",
    "        t0 = time.time()\n",
    "        distances, indices = knn.kneighbors(orow[['oa_lon','oa_lat']].values.reshape(1, -1))\n",
    "        t1 = time.time()\n",
    "        processing_time += (t1 - t0)\n",
    "        \n",
    "        oCosts = []\n",
    "        oTrips = 0\n",
    "        oTimes = 0\n",
    "\n",
    "        for i in indices[0]:\n",
    "            pid = POISample.iloc[i]['poi_id']\n",
    "            #trips_sample = trips[(trips['oa_id'] == orow['oa_id']) & (trips['poi_id'] == pid)]\n",
    "            trips_sample = trips.loc[oa_poi_id_dict[orow['oa_id']][pid]]\n",
    "            oCosts = oCosts + list(trips_sample['gac'])\n",
    "            oTrips += len(trips_sample)\n",
    "            oTimes += trips_sample['queryTime'].sum()\n",
    "\n",
    "        kResAppend = {}\n",
    "        kResAppend['oa_id'] = orow['oa_id']\n",
    "        kResAppend['score'] = statistics.mean(oCosts)\n",
    "        kResAppend['times'] = oTimes\n",
    "        kResList.append(kResAppend)\n",
    "\n",
    "    knnres = pd.DataFrame(kResList).set_index('oa_id')\n",
    "\n",
    "    peformance_mx['knn_{}'.format(k)] = knnres['score']\n",
    "    costing_mx['KNN_{}'.format(k)] = knnres['times']\n",
    "    computing_times['KNN_{}'.format(k)] = processing_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Test : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3469982662.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Test : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3469982662.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Test : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3469982662.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Test : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3469982662.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Test : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3469982662.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Test : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3469982662.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Test : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3469982662.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Test : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3469982662.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    }
   ],
   "source": [
    "for num_clusters in [3,4,5,6,7,8,9,10]:\n",
    "\n",
    "    print('Next Test : {}'.format(num_clusters))\n",
    "\n",
    "    processing_time = 0\n",
    "\n",
    "    t0 = time.time()\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=0, n_init=\"auto\").fit(POISample[['poi_lon','poi_lat']].values)\n",
    "    # Get cluster labels and centroids\n",
    "    cluster_labels = kmeans.labels_\n",
    "    t1 = time.time()\n",
    "    processing_time += (t1 - t0)\n",
    "\n",
    "    POISample['cluster'] = cluster_labels\n",
    "\n",
    "    flows_df_list = []\n",
    "\n",
    "    for cluster in set(cluster_labels):\n",
    "        t0 = time.time()\n",
    "        points_in_cluster = np.where(cluster_labels == cluster)[0]\n",
    "        centroid = [POISample[POISample['cluster'] == cluster]['poi_lon'].mean(),POISample[POISample['cluster'] == cluster]['poi_lat'].mean()]\n",
    "        distances_to_centroid = np.linalg.norm(POISample[['poi_lon','poi_lat']].values[points_in_cluster] - POISample[['poi_lon','poi_lat']].values[points_in_cluster].mean(axis = 0), axis=1)\n",
    "        # Find the index of the point closest to the centroid\n",
    "        closest_point_index = points_in_cluster[np.argmin(distances_to_centroid)]\n",
    "        flow_id = POISample.iloc[closest_point_index]['poi_id']\n",
    "        t1 = time.time()\n",
    "        processing_time += (t1 - t0)\n",
    "        oa_count = 0\n",
    "        for oa in list(oaSample['oa_id']):\n",
    "            oa_count += 1\n",
    "            flow_gac = trips.loc[oa_poi_id_dict[oa][flow_id]][['oa_id','poi_id','time','gac','queryTime']]\n",
    "            query_times = list(flow_gac['queryTime'])\n",
    "\n",
    "            for poi in points_in_cluster:\n",
    "                flow_append = flow_gac.copy()\n",
    "                if poi != closest_point_index:\n",
    "                    flow_append['queryTime'] = 0\n",
    "                else:\n",
    "                    flow_append['queryTime'] = query_times\n",
    "                flow_append['poi_id'] = POISample.iloc[poi]['poi_id']\n",
    "                flows_df_list.append(flow_append)\n",
    "\n",
    "    flows_df = pd.concat(flows_df_list, ignore_index=True)\n",
    "    flows_df['att'] = flows_df['poi_id'].map(attractivnessDict)\n",
    "    flows_df['dist decay'] = vfunc(np.array(flows_df['gac']),decay_constant, exponent)\n",
    "    flows_df['grav'] = flows_df['dist decay'] * flows_df['att']\n",
    "    peformance_mx['kmean_{}'.format(num_clusters)] = flows_df.groupby('oa_id').sum()['grav']\n",
    "    costing_mx['kmean_{}'.format(num_clusters)] = flows_df.groupby('oa_id').sum()['queryTime']\n",
    "    computing_times['kmean_{}'.format(num_clusters)] = processing_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/336290671.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/336290671.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/336290671.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/336290671.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/336290671.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/336290671.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/336290671.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/336290671.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/336290671.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    }
   ],
   "source": [
    "eps_test = [0.01,0.02,0.03]\n",
    "min_samples = [1,3,5]\n",
    "\n",
    "for ep in eps_test:\n",
    "    for ms in min_samples:\n",
    "        processing_time = 0\n",
    "\n",
    "        t0 = time.time()\n",
    "        dbscan = DBSCAN(eps=ep, min_samples=ms).fit(POISample[['poi_lon','poi_lat']].values)\n",
    "\n",
    "        # Get cluster labels and centroids\n",
    "        cluster_labels = dbscan.labels_\n",
    "        POISample['cluster'] = cluster_labels\n",
    "        t1 = time.time()\n",
    "        processing_time += (t1 - t0)\n",
    "        flows_df_list = []\n",
    "\n",
    "        for cluster in set(cluster_labels):\n",
    "            if cluster == -1:\n",
    "                for c_ind in np.where(cluster_labels == cluster)[0]:\n",
    "                    flow_id = POISample.iloc[c_ind]['poi_id']\n",
    "\n",
    "                    for oa in list(oaSample['oa_id']):\n",
    "                        flow_gac = trips.loc[oa_poi_id_dict[oa][flow_id]][['oa_id','poi_id','time','gac','queryTime']]\n",
    "                        flows_df_list.append(flow_gac)\n",
    "            else:\n",
    "                t0 = time.time()\n",
    "                points_in_cluster = np.where(cluster_labels == cluster)[0]\n",
    "                centroid = [POISample[POISample['cluster'] == cluster]['poi_lon'].mean(),POISample[POISample['cluster'] == cluster]['poi_lat'].mean()]\n",
    "                distances_to_centroid = np.linalg.norm(POISample[['poi_lon','poi_lat']].values[points_in_cluster] - POISample[['poi_lon','poi_lat']].values[points_in_cluster].mean(axis = 0), axis=1)\n",
    "                # Find the index of the point closest to the centroid\n",
    "                closest_point_index = points_in_cluster[np.argmin(distances_to_centroid)]\n",
    "                flow_id = POISample.iloc[closest_point_index]['poi_id']\n",
    "                t1 = time.time()\n",
    "                processing_time += (t1 - t0)\n",
    "                for oa in list(oaSample['oa_id']):\n",
    "                    flow_gac = trips.loc[oa_poi_id_dict[oa][flow_id]][['oa_id','poi_id','time','gac','queryTime']]\n",
    "                    query_times = list(flow_gac['queryTime'])\n",
    "                    for poi in points_in_cluster:\n",
    "                        flow_append = flow_gac.copy()\n",
    "                        if poi != closest_point_index:\n",
    "                            flow_append['queryTime'] = 0\n",
    "                        else:\n",
    "                            flow_append['queryTime'] = query_times\n",
    "                        flow_append['poi_id'] = POISample.iloc[poi]['poi_id']\n",
    "                        flows_df_list.append(flow_append)\n",
    "\n",
    "        flows_df = pd.concat(flows_df_list, ignore_index=True)\n",
    "        flows_df['att'] = flows_df['poi_id'].map(attractivnessDict)\n",
    "        flows_df['dist decay'] = vfunc(np.array(flows_df['gac']),decay_constant, exponent)\n",
    "        flows_df['grav'] = flows_df['dist decay'] * flows_df['att']\n",
    "        peformance_mx['dbscan_{}_{}'.format(ep,ms)] = flows_df.groupby('oa_id').sum()['grav']\n",
    "        costing_mx['dbscan_{}_{}'.format(ep,ms)] = flows_df.groupby('oa_id').sum()['queryTime']\n",
    "        computing_times['dbscan_{}_{}'.format(ep,ms)] = processing_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3774843614.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels : [ 3  3  7  1 -1  3  5  5  7  4  2  6  6  2  7  4 -1  0  1  6  3  6  2  2\n",
      "  2  2  1  2 -1 -1  5  5  5  7  5  7  7  7  5  6  6  6  6 -1  4  0  7  6\n",
      "  0  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3774843614.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels : [ 1  1  6  2 -1  1  4  4  5  1 -1  5 -1  3  6  1 -1  0  2  5  1  5  3  3\n",
      "  3  3  2  3 -1 -1  4  4  4 -1  4  6 -1  6 -1  5  5  5  5 -1  1  0  6  5\n",
      "  0  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3774843614.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels : [ 0  0  0  1  1  0  0  0  0  0  1  0  0  1  0  0 -1  0  1  0  0  0  1  1\n",
      "  1  1  1  1  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0 -1  0 -1  0  0\n",
      "  0  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3774843614.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels : [ 0  0  0  1  1  0  0  0  0  0  1  0  0  1  0  0 -1 -1  1  0  0  0  1  1\n",
      "  1  1  1  1  0 -1 -1  0  0  0  0  0 -1 -1  0  0  0  0  0 -1  0 -1  0  0\n",
      " -1  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3774843614.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels : [ 1  1  4  0  0  1  2  2  4  1  0  3  3  0  4  1 -1 -1  0  3  1  3  0  0\n",
      "  0  0  0  0 -1 -1  2  2  2  4  2  4  4  4  2  3  3  3  3 -1  1 -1  4  3\n",
      " -1  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3774843614.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels : [ 1  1  4  0  0  1  2  2  3  1  0  3 -1  0  4  1 -1 -1  0  3  1  3  0  0\n",
      "  0  0  0  0  0 -1  2  2  2 -1  2  4 -1  4 -1  3  3  3  3 -1  1 -1  4  3\n",
      " -1  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3774843614.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels : [ 0  0  0  1  1  0  0  0  0  0  1  0  0  1  0  0 -1  0  1  0  0  0  1  1\n",
      "  1  1  1  1  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0 -1  0 -1  0  0\n",
      "  0  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3774843614.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels : [ 0  0  0  1  1  0  0  0  0  0  1  0  0  1  0  0 -1 -1  1  0  0  0  1  1\n",
      "  1  1  1  1  0 -1 -1  0  0  0  0  0 -1 -1  0  0  0  0  0 -1  0 -1  0  0\n",
      " -1  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3774843614.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels : [ 1  1  4  0  0  1  2  2  4  1  0  3  3  0  4  1 -1 -1  0  3  1  3  0  0\n",
      "  0  0  0  0 -1 -1  2  2  2  4  2  4  4  4  2  3  3  3  3 -1  1 -1  4  3\n",
      " -1  4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3774843614.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels : [ 0  0  0  1  1  0  0  0  0  0  1  0  0  1  0  0 -1  0  1  0  0  0  1  1\n",
      "  1  1  1  1  1  0  0  0  0  0  0  0 -1  0  0  0  0  0  0 -1  0  0  0  0\n",
      "  0  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3774843614.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels : [ 0  0  0  1  1  0  0  0  0  0  1  0  0  1  0  0 -1  0  1  0  0  0  1  1\n",
      "  1  1  1  1  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0 -1  0 -1  0  0\n",
      "  0  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960/3774843614.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  POISample['cluster'] = cluster_labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels : [ 0  0  0  1  1  0  0  0  0  0  1  0  0  1  0  0 -1 -1  1  0  0  0  1  1\n",
      "  1  1  1  1  0 -1 -1  0  0  0  0  0 -1 -1  0  0  0  0  0 -1  0 -1  0  0\n",
      " -1  0]\n"
     ]
    }
   ],
   "source": [
    "min_clusters = [3,5,7]\n",
    "min_sample_tests = [1,3,5,7]\n",
    "\n",
    "for mc in min_clusters:\n",
    "    for ms in min_sample_tests:\n",
    "\n",
    "        processing_time = 0\n",
    "\n",
    "        t0 = time.time()\n",
    "        hdbscan = HDBSCAN(min_cluster_size = mc, min_samples=ms).fit(POISample[['poi_lon','poi_lat']].values)\n",
    "\n",
    "        # Get cluster labels and centroids\n",
    "        cluster_labels = hdbscan.labels_\n",
    "        POISample['cluster'] = cluster_labels\n",
    "        t1 = time.time()\n",
    "        processing_time += (t1 - t0)\n",
    "        print('Cluster Labels : {}'.format(cluster_labels))\n",
    "\n",
    "        flows_df_list = []\n",
    "\n",
    "        for cluster in set(cluster_labels):\n",
    "            if cluster == -1:\n",
    "                for c_ind in np.where(cluster_labels == cluster)[0]:\n",
    "                    flow_id = POISample.iloc[c_ind]['poi_id']\n",
    "\n",
    "                    for oa in list(oaSample['oa_id']):\n",
    "                        flow_gac = trips.loc[oa_poi_id_dict[oa][flow_id]][['oa_id','poi_id','time','gac','queryTime']]\n",
    "                        flows_df_list.append(flow_gac)\n",
    "            else:\n",
    "                t0 = time.time()\n",
    "                points_in_cluster = np.where(cluster_labels == cluster)[0]\n",
    "                centroid = [POISample[POISample['cluster'] == cluster]['poi_lon'].mean(),POISample[POISample['cluster'] == cluster]['poi_lat'].mean()]\n",
    "                distances_to_centroid = np.linalg.norm(POISample[['poi_lon','poi_lat']].values[points_in_cluster] - POISample[['poi_lon','poi_lat']].values[points_in_cluster].mean(axis = 0), axis=1)\n",
    "                # Find the index of the point closest to the centroid\n",
    "                closest_point_index = points_in_cluster[np.argmin(distances_to_centroid)]\n",
    "                flow_id = POISample.iloc[closest_point_index]['poi_id']\n",
    "                t1 = time.time()\n",
    "                processing_time += (t1 - t0)\n",
    "                for oa in list(oaSample['oa_id']):\n",
    "                    flow_gac = trips.loc[oa_poi_id_dict[oa][flow_id]][['oa_id','poi_id','time','gac','queryTime']]\n",
    "                    query_times = list(flow_gac['queryTime'])\n",
    "                    for poi in points_in_cluster:\n",
    "                        flow_append = flow_gac.copy()\n",
    "                        if poi != closest_point_index:\n",
    "                            flow_append['queryTime'] = 0\n",
    "                        else:\n",
    "                            flow_append['queryTime'] = query_times\n",
    "                        flow_append['poi_id'] = POISample.iloc[poi]['poi_id']\n",
    "                        flows_df_list.append(flow_append)\n",
    "\n",
    "        flows_df = pd.concat(flows_df_list, ignore_index=True)\n",
    "        flows_df['att'] = flows_df['poi_id'].map(attractivnessDict)\n",
    "        flows_df['dist decay'] = vfunc(np.array(flows_df['gac']),decay_constant, exponent)\n",
    "        flows_df['grav'] = flows_df['dist decay'] * flows_df['att']\n",
    "        peformance_mx['hdbscan_{}_{}'.format(mc,ms)] = flows_df.groupby('oa_id').sum()['grav']\n",
    "        costing_mx['hdbscan_{}_{}'.format(mc,ms)] = flows_df.groupby('oa_id').sum()['queryTime']\n",
    "        computing_times['hdbscan_{}_{}'.format(mc,ms)] = processing_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get results flow clusering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do\n",
    "\n",
    "- Function to get distace matrix\n",
    "- Test correlation over a set of parameters\n",
    "- Collect metrics\n",
    "- Time traps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDBSCAN with flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161  88 274 ... 762 639 756]\n",
      "[ 56  32  59 ... 430 362 440]\n",
      "[ -1  77  66 ... 107  27  88]\n",
      "[ 38  20  80 ... 330 198 337]\n",
      "[ 65  34  68 ... 148  57 141]\n",
      "[-1 76 68 ... 87 14 69]\n",
      "[ 38  19  76 ... 322 190 329]\n",
      "[85 57 92 ... 93  7 89]\n",
      "[94 76 68 ... 87 14 69]\n",
      "[162  73 210 ... 692 409 691]\n",
      "[ 47  31  58 ... 411 339 429]\n",
      "[-1 71 63 ... 98 13 87]\n",
      "[ 40  20  85 ... 389 180 383]\n",
      "[ 55  33  66 ... 137  44 145]\n",
      "[-1 74 70 ... 87 18 67]\n",
      "[ 34  18  76 ... 333 146 327]\n",
      "[70 55 93 ... 86  7 90]\n",
      "[94 74 70 ... 87 18 67]\n",
      "[165 222 276 ... 705 624 673]\n",
      "[ 79  38  62 ... 341 292 369]\n",
      "[-1 81 51 ... 98 35 79]\n",
      "[105 113 158 ... 352 196 333]\n",
      "[109  48  78 ...  94  59 134]\n",
      "[-1 76 56 ... 87 12 53]\n",
      "[31 28 38 ... 42  2 37]\n",
      "[93 61 89 ... 72  3 74]\n",
      "[94 76 56 ... 87 12 53]\n"
     ]
    }
   ],
   "source": [
    "# Get flow\n",
    "# Cluster flows\n",
    "\n",
    "minflows = [3,5,7]\n",
    "minclusters = [5,10,15]\n",
    "minsamples = [5,10,15]\n",
    "        \n",
    "for mf in minflows:\n",
    "    X, o_index, d_index, flows, flows_index = get_flow_dist_mx(oaSample,POISample,mf,flowProx)\n",
    "    for mc in minclusters:\n",
    "        for ms in minsamples:\n",
    "            \n",
    "            processing_time = 0\n",
    "\n",
    "            t0 = time.time()\n",
    "            hdb = HDBSCAN(min_cluster_size=mc, min_samples=ms, metric=getminreach).fit(X)\n",
    "            cluster_labels = hdb.labels_\n",
    "            t1 = time.time()\n",
    "            processing_time += (t1 - t0)\n",
    "            print(cluster_labels)\n",
    "\n",
    "            flows_df_list = []\n",
    "            for cluster in set(cluster_labels):\n",
    "                if cluster == -1:\n",
    "                    cluster_indeces = np.where(cluster_labels==cluster)[0]\n",
    "                    flow_inds = list(set([flows_index[i] for i in cluster_indeces]))\n",
    "                    for f in flow_inds:\n",
    "                        flow_gac = trips.loc[oa_poi_id_dict[f[0]][f[1]]][['oa_id','poi_id','time','gac','queryTime']]\n",
    "                        flows_df_list.append(flow_gac)\n",
    "                else:\n",
    "                    t0 = time.time()\n",
    "                    cluster_indeces = np.where(cluster_labels==cluster)[0]\n",
    "                    #Select origin of best flow\n",
    "                    oas_in_flow = list(set([o_index[i] for i in cluster_indeces]))\n",
    "                    distances_to_centroid = np.linalg.norm(oaSample.set_index('oa_id').loc[oas_in_flow].values - oaSample.set_index('oa_id').loc[oas_in_flow].values.mean(axis = 0),axis=1)\n",
    "                    flow_oa = oas_in_flow[np.argmin(distances_to_centroid)]\n",
    "                    #Select destination of best flow\n",
    "                    poi_ids = list(set([d_index[i] for i in cluster_indeces]))\n",
    "                    distances_to_centroid = np.linalg.norm(POISample.set_index('poi_id').loc[poi_ids][['poi_lon','poi_lat']].values - POISample.set_index('poi_id').loc[poi_ids][['poi_lon','poi_lat']].values.mean(axis = 0),axis = 1)\n",
    "                    flow_poi = poi_ids[np.argmin(distances_to_centroid)]\n",
    "                    t1 = time.time()\n",
    "                    processing_time += (t1 - t0)\n",
    "                    #measure GAC for all time steps\n",
    "                    flow_gac = trips.loc[oa_poi_id_dict[flow_oa][flow_poi]][['oa_id','poi_id','time','gac','queryTime']]\n",
    "                    query_times = list(flow_gac['queryTime'])\n",
    "                    flow_inds = list(set([flows_index[i] for i in cluster_indeces]))\n",
    "                    for f in flow_inds:\n",
    "                        flow_append = flow_gac.copy()\n",
    "                        if f[1] != flow_poi:\n",
    "                            flow_append['queryTime'] = 0\n",
    "                        else:\n",
    "                            flow_append['queryTime'] = query_times\n",
    "                        flow_append['oa_id'] = f[0]\n",
    "                        flow_append['poi_id'] = f[1]\n",
    "                        flows_df_list.append(flow_append)\n",
    "            flows_df = pd.concat(flows_df_list, ignore_index=True)\n",
    "            flows_df['att'] = flows_df['poi_id'].map(attractivnessDict)\n",
    "            flows_df['dist decay'] = vfunc(np.array(flows_df['gac']),decay_constant, exponent)\n",
    "            flows_df['grav'] = flows_df['dist decay'] * flows_df['att']\n",
    "            peformance_mx['flowhdbscan_{}_{}_{}'.format(mf,mc,ms)] = flows_df.groupby('oa_id').sum()['grav']\n",
    "            costing_mx['flowhdbscan_{}_{}_{}'.format(mf,mc,ms)] = flows_df.groupby('oa_id').sum()['queryTime']\n",
    "            computing_times['flowhdbscan_{}_{}_{}'.format(mf,mc,ms)] = processing_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Results trip generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#METHOD 1 - Trip Generator (Gravity)\n",
    "\n",
    "distMxList = []\n",
    "\n",
    "for i,r in oas.iterrows():\n",
    "    for i_, r_ in pois.iterrows():\n",
    "        rowAppend = {}\n",
    "        rowAppend['oa'] = r['oa_id']\n",
    "        rowAppend['poi'] = r_['poi_id']\n",
    "        rowAppend['dist'] = haversine(r['oa_lon'], r['oa_lat'], r_['poi_lon'], r_['poi_lat'])\n",
    "        distMxList.append(rowAppend)\n",
    "\n",
    "distMx = pd.DataFrame(distMxList)\n",
    "\n",
    "distMx['att'] = distMx['poi'].map(attractivnessDict)\n",
    "\n",
    "distsDecay = []\n",
    "for i in np.array(distMx['dist']):\n",
    "    distsDecay.append(distance_decay(i, decay_constant, exponent))\n",
    "\n",
    "distMx['decay'] = distsDecay\n",
    "distMx['grav'] = distMx['decay'] * distMx['att']\n",
    "distMx['gravN'] = (distMx['grav'] - distMx['grav'].min()) / (distMx['grav'].max() - distMx['grav'].min())\n",
    "distMx = distMx.merge(tripsL.groupby(['oa_id','poi_id']).count()['departure_time'].rename('tripCount'), left_on = ['oa','poi'],right_index = True)\n",
    "distMx['tripsSample'] = distMx['tripCount'] * distMx['gravN']\n",
    "\n",
    "resultsList = []\n",
    "\n",
    "countOrigins = 0\n",
    "\n",
    "print('Running Trip Gen Gravity')\n",
    "\n",
    "for o in oaIndex:\n",
    "    countOrigins += 1\n",
    "    if countOrigins % 20 == 0:\n",
    "        print(countOrigins)\n",
    "    oCosts = []\n",
    "    oTrips = 0\n",
    "    oTimes = 0\n",
    "    for p in poiIndex:\n",
    "    \n",
    "        numSample = int(distMx[(distMx['oa'] == o) & (distMx['poi'] == p)]['tripsSample'].values[0])\n",
    "        tripSample = tripsL[(tripsL['oa_id'] == o) & (tripsL['poi_id'] == p)].sample(numSample)\n",
    "        oCosts = oCosts + list(tripSample[cost])\n",
    "        oTrips += numSample\n",
    "        oTimes += tripSample['queryTime'].sum()\n",
    "\n",
    "    \n",
    "    rowAppend = {}\n",
    "    rowAppend['OA'] = o\n",
    "    rowAppend['GTG'] = statistics.mean(oCosts)\n",
    "    rowAppend['GTG_Trips'] = oTrips\n",
    "    rowAppend['GTG_Times'] = oTimes\n",
    "    resultsList.append(rowAppend)\n",
    "\n",
    "tripGenGrav = pd.DataFrame(resultsList)\n",
    "zoneLevelResults = tripGenGrav.merge(gravity, left_on = 'OA', right_index = True)\n",
    "\n",
    "print('Fnished trip gen grav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "\n",
    "- Any optimisations needed?\n",
    "- Add in code from previous version\n",
    "- Add to metrics\n",
    "- Add time trap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General to dos after script finished\n",
    "\n",
    "- Put into single python script and test locally on small number of OAs and POIs\n",
    "- Script parameters\n",
    "    - Number of OAs\n",
    "    - Number of POIs\n",
    "    - Temporal granularity\n",
    "    - Parallelisation metrics\n",
    "- Carefully check all outputs as expected and initial analysis of results\n",
    "- Set up server on digital ocean which can parallise over 30+ instaces\n",
    "- Upload all data etc\n",
    "- Run test script to check\n",
    "    - Trip costing working e.g., GAC generating as expected (e.g., add trips output to observe)\n",
    "    - Check parallisation works and does not break server\n",
    "    - Check results are as expected\n",
    "- Extend to run on full set of experiments\n",
    "- Run observe for a while, predict how long it'll take and make sure not too costly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "access",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
