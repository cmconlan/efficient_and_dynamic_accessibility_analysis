{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_372296/3209103574.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import Point\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in days from GTFS\n",
    "\n",
    "gtfs_dates = pd.read_csv('data/tfwm_gtfs/calendar_dates.txt', parse_dates=[1])\n",
    "date_counts = gtfs_dates['date'].value_counts().sort_index()\n",
    "\n",
    "#Filter 15th March to 15th April\n",
    "\n",
    "start_date = '2023-03-15'\n",
    "end_date = '2024-04-15'\n",
    "\n",
    "date_counts = pd.DataFrame(date_counts.loc[start_date:end_date])\n",
    "\n",
    "date_counts['weekday'] = date_counts.index.weekday < 5\n",
    "\n",
    "bank_holidays = ['2024-03-29', '2024-04-01']\n",
    "date_counts['bank_holiday'] = date_counts.index.isin(pd.to_datetime(bank_holidays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get random date\n",
    "\n",
    "rand_date1 = date_counts[((date_counts['weekday'] == True) & (date_counts['bank_holiday'] == False))].sample(1).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2024-04-10'], dtype='datetime64[ns]', name='date', freq=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_date1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_date = date_counts[((date_counts['weekday'] == True) & (date_counts['bank_holiday'] == False))].iloc[:1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2024-01-29'], dtype='datetime64[ns]', name='date', freq=None)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OAs\n",
    "\n",
    "wm_oas = gpd.read_file('data/west_midlands_OAs/west_midlands_OAs.shp')\n",
    "wm_oas = wm_oas[wm_oas['LAD11CD'] == 'E08000026']\n",
    "oa_info = pd.read_csv('data/oa_info.csv')\n",
    "oa_info = oa_info.merge(wm_oas[['OA11CD']], left_on = 'oa_id', right_on = 'OA11CD', how = 'inner')\n",
    "oaLatLon = oa_info[['oa_id','oa_lon','oa_lat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get POIs\n",
    "\n",
    "pois = pd.read_csv('data/POIs/pois.csv', index_col=0)\n",
    "\n",
    "#Select local POIs\n",
    "poisInRegion = []\n",
    "\n",
    "for i,r in pois.iterrows():\n",
    "    poiPoint = Point(tuple(list(r[['poi_lon','poi_lat']])))\n",
    "    \n",
    "    for i2, r2 in wm_oas.iterrows():\n",
    "        if r2['geometry'].intersects(poiPoint):\n",
    "            poisInRegion.append(r['poi_id'])\n",
    "\n",
    "pois = pois[pois['poi_id'].isin(poisInRegion)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Time Stamps / Time Interval\n",
    "\n",
    "stratumDict = {\n",
    "    'amPeak':{\n",
    "        'startHour' : 6,\n",
    "        'startMinute' : 30,\n",
    "        'endHour' : 8,\n",
    "        'endMinute' : 30,\n",
    "        'day':'tues'\n",
    "        },\n",
    "    'interPeak':{\n",
    "        'startHour' : 11,\n",
    "        'startMinute' : 00,\n",
    "        'endHour' : 16,\n",
    "        'endMinute' : 00,\n",
    "        'day':'tues'\n",
    "        },\n",
    "    'pmPeak':{\n",
    "        'startHour' : 16,\n",
    "        'startMinute' : 30,\n",
    "        'endHour' : 18,\n",
    "        'endMinute' : 30,\n",
    "        'day':'tues'\n",
    "        },\n",
    "    'Saturday':{\n",
    "        'startHour' : 10,\n",
    "        'startMinute' : 00,\n",
    "        'endHour' : 18,\n",
    "        'endMinute' : 00,\n",
    "        'day' : 'sat'\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratum = 'amPeak'\n",
    "\n",
    "# Create Time Domain\n",
    "startHour = stratumDict[stratum]['startHour']\n",
    "startMinute = stratumDict[stratum]['startMinute']\n",
    "endHour = stratumDict[stratum]['endHour']\n",
    "endMinute = stratumDict[stratum]['endMinute']\n",
    "\n",
    "start = datetime.datetime(year=2012, month=2, day=25, hour=startHour, minute = startMinute)\n",
    "end = datetime.datetime(year=2012, month=2, day=25, hour=endHour, minute = endMinute)\n",
    "diff = end - start\n",
    "minutesInInterval = diff.total_seconds()/60\n",
    "hoursInInterval = minutesInInterval/60\n",
    "\n",
    "timeDomain = []\n",
    "\n",
    "for i in range(300):\n",
    "    randStartTime = start + timedelta(minutes=random.randint(1, int(minutesInInterval)))\n",
    "    timeDomain.append(str(randStartTime.hour).zfill(2)+':'+str(randStartTime.minute).zfill(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os, urllib, json, csv, zipfile, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Rows : 1134\n",
      "0\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Rows : 66\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'plan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     55\u001b[0m objs \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(content)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mobjs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitineraries\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     57\u001b[0m     fail_append \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     58\u001b[0m     fail_append[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moa\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m next_oa[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moa_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'plan'"
     ]
    }
   ],
   "source": [
    "oa_sample = random.sample(list(oaLatLon.index), 2)\n",
    "poi_sample = pois[pois['type']=='Vaccination Centre'].index\n",
    "time_sample = random.sample(range(len(timeDomain)), 3)\n",
    "\n",
    "print('Num Rows : {}'.format(len(oa_sample) * len(poi_sample) * len(time_sample)))\n",
    "\n",
    "otp_url = 'http://localhost:8080/otp/routers/default/plan?'\n",
    "output_file = open('tempdata/tripscosts.csv', 'w')\n",
    "writer = csv.writer(output_file)\n",
    "writer.writerow(['trip_id','date','time','oa_id','poi_id','itiniery_id','duration','walk_time','wait_time','transit_time','transfers','fare'])\n",
    "\n",
    "trip_id = 0\n",
    "trip_date = rand_date[0].strftime('%m/%d/%Y')\n",
    "\n",
    "failed_routes_list = []\n",
    "\n",
    "for oa_ind in oa_sample:\n",
    "    for poi_ind in poi_sample:\n",
    "        for t_ind in time_sample:\n",
    "            if trip_id % 500 == 0:\n",
    "                print(trip_id)\n",
    "            next_oa = oaLatLon.loc[oa_ind]\n",
    "            next_poi = pois.loc[poi_ind]\n",
    "            trip_time = timeDomain[t_ind]\n",
    "\n",
    "            params = {}\n",
    "\n",
    "            params['date'] = trip_date\n",
    "            params['trip_time'] = trip_time\n",
    "            params['fromPlace'] = '%s,%s' % (next_oa['oa_lat'], next_oa['oa_lon'])\n",
    "            params['toPlace'] = '%s,%s' % (next_poi['poi_lat'], next_poi['poi_lon'])\n",
    "            params['maxWalkDistance'] = 2000\n",
    "            params['mode'] = 'WALK,TRANSIT'\n",
    "            params['numItineraries'] = 1\n",
    "            params['arriveBy'] = 'false'\n",
    "            params['searchWindow'] = 600\n",
    "            # params['minWindow'] = '1M'\n",
    "            # params['maxWindow'] = '1M'\n",
    "            # params['minTransitTimeCoefficient'] = 0\n",
    "            # params['minWaitTimeCoefficient'] = 0\n",
    "            # params['minTransitTime'] = '1M'\n",
    "            # params['transit'] = {}\n",
    "            # params['transit']['dynamicSearchWindow'] = {}\n",
    "            # params['transit']['dynamicSearchWindow']['minWindow'] = 'adfigheajriugf'\n",
    "            # params['transit']['dynamicSearchWindow']['maxWindow'] = 'PT1M'\n",
    "            # params['transit']['dynamicSearchWindow']['minTransitTimeCoefficient'] = 0\n",
    "            # params['transit']['dynamicSearchWindow']['minWaitTimeCoefficient'] = 0\n",
    "\n",
    "            req = urllib.request.Request(otp_url + urllib.parse.urlencode(params))\n",
    "            req.add_header('Accept', 'application/json')\n",
    "\n",
    "            response = urllib.request.urlopen(req)\n",
    "\n",
    "            content = response.read()\n",
    "            objs = json.loads(content)\n",
    "            if len(objs['plan']['itineraries']) == 0:\n",
    "                fail_append = {}\n",
    "                fail_append['oa'] = next_oa['oa_id']\n",
    "                fail_append['poi'] = next_poi['poi_id']\n",
    "                fail_append['time'] = trip_time\n",
    "                failed_routes_list.append(fail_append)\n",
    "                pass\n",
    "            # else:\n",
    "            #     i = objs['plan']['itineraries'][0]\n",
    "            itin_id = 1\n",
    "            for i in objs['plan']['itineraries']:\n",
    "                #compute fare\n",
    "                if i['transitTime'] == 0:\n",
    "                    fare = 0\n",
    "                else:\n",
    "                    fare = (i['transfers'] + 1) * 2.4\n",
    "\n",
    "                row = [trip_id,trip_date,trip_time,next_oa['oa_id'],next_poi['poi_id'],itin_id,i['duration'],i['walkTime'],i['waitingTime'],i['transitTime'],i['transfers'],fare]\n",
    "                writer.writerow(row)\n",
    "                itin_id += 1\n",
    "\n",
    "            trip_id += 1\n",
    "\n",
    "output_file.close()\n",
    "failed_routes = pd.DataFrame(failed_routes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'requestParameters': {'date': '01/29/2024',\n",
       "  'mode': 'WALK,TRANSIT',\n",
       "  'trip_time': '14:55',\n",
       "  'arriveBy': 'false',\n",
       "  'fromPlace': '52.39377486,-1.584882656',\n",
       "  'toPlace': '52.3897625066329,-1.46366887755254',\n",
       "  'searchWindow': 'null',\n",
       "  'maxWalkDistance': '2000',\n",
       "  'numItineraries': '1'},\n",
       " 'error': {'id': 500,\n",
       "  'msg': \"We're sorry. The trip planner is temporarily unavailable. Please try again later.\",\n",
       "  'message': 'SYSTEM_ERROR'}}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gen access cost\n",
    "#(( 1.5 * (labelledTrips['total_time'])) - (0.5 * labelledTrips['transit_time']) + ((labelledTrips['fare'] * 3600) / 6.7) + (10 * labelledTrips['num_transfers'])) / 60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "access",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
